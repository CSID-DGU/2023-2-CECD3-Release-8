{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "17vLGR1IpSbr31DZZDR0JeFbSjqG7qgNk",
      "authorship_tag": "ABX9TyOndofHqPutlwov54BBDFXb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doSeung11/2023-2-CECD3-Release-8/blob/main/JangguSound86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "CA5lkfTAjbEA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo pip install numba\n",
        "!sudo pip install llvmlite\n",
        "!sudo pip install librosa\n",
        "!sudo apt-get install ffmpeg\n",
        "!sudo pip install resampy\n",
        "!sudo pip install keras\n",
        "!sudo pip install np_utils\n",
        "\n",
        "#한글 깨짐 방지\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "metadata": {
        "id": "wdTbq54-w6X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.preprocessing\n",
        "max_ped_len = 86\n",
        "\n",
        "def extract_features(file_name):\n",
        "\n",
        "    try:\n",
        "        wav, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
        "        mfcc = librosa.feature.mfcc(y=wav, sr=sample_rate, n_mfcc=100)\n",
        "\n",
        "        pad_width = max_ped_len - mfcc.shape[1]\n",
        "        mfcc = np.pad(mfcc, pad_width=((0,0), (0,pad_width)),mode='constant')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error encountered: \", e)\n",
        "        return None\n",
        "\n",
        "    return mfcc\n",
        "\n",
        "fulldatasetpath = '/content/drive/MyDrive/CSE/trainset/'\n",
        "features = []\n",
        "\n",
        "#Iterate through each sound file and extract the features\n",
        "for file_name in os.listdir(fulldatasetpath):\n",
        "\n",
        "    if 'wav' not in file_name:\n",
        "      continue\n",
        "\n",
        "    data = extract_features(fulldatasetpath+file_name)\n",
        "    class_label = file_name[0:3]\n",
        "\n",
        "    features.append([data, class_label])\n",
        "\n",
        "#Convert into a Panda dataframe\n",
        "featuresdf = pd.DataFrame(features, columns=['feature', 'class_label'])\n",
        "\n",
        "print('Finished feature extraction from ', len(featuresdf), ' files')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uCpZYhBxF1v",
        "outputId": "2effb718-6797-4928-d9f1-089592267996"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished feature extraction from  300  files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 데이터와 훈련 데이터 분할\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#Convert features and corresponding classification labels into numpy arrays\n",
        "X = np.array(featuresdf.feature.tolist())\n",
        "\n",
        "y = np.array(featuresdf.class_label.tolist())\n",
        "\n",
        "#Encode the classification labels\n",
        "le = LabelEncoder()\n",
        "yy = to_categorical(le.fit_transform(y))\n",
        "\n",
        "#Split the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "8oXt_0Eqx87p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d36bca-62c3-48b1-c38b-8e26f78b467c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(240, 100, 86)\n",
            "(60, 100, 86)\n",
            "(240, 3)\n",
            "(60, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN model\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from sklearn import metrics\n",
        "\n",
        "num_rows = 100\n",
        "num_columns = 86\n",
        "num_channel = 1\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channel)\n",
        "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channel)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "num_labels = yy.shape[1]\n",
        "filter_size = 2\n",
        "\n",
        "# Construct model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(x_train.shape[1],  x_train.shape[2], num_channel), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))"
      ],
      "metadata": {
        "id": "6MbPLL0SyEsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31786abe-3249-4851-c702-0bdc2014954d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(240, 100, 86, 1)\n",
            "(60, 100, 86, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 컴파일\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "# Display model architecture summary\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#학습 데이터로 모델 훈련\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime\n",
        "\n",
        "num_epochs = 150\n",
        "num_batch_size = 32\n",
        "\n",
        "#checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_cnn.hdf5', verbose=1, save_best_only=True)\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size = num_batch_size,\n",
        "                    epochs = num_epochs,\n",
        "                    validation_data = (x_test, y_test),\n",
        "                    verbose = 1)\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvjXaBsIyZGP",
        "outputId": "bce0a451-8fa7-43ad-e998-750e7ec4dbc3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 99, 85, 16)        80        \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 49, 42, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 49, 42, 16)        0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 48, 41, 32)        2080      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 24, 20, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 24, 20, 32)        0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 23, 19, 64)        8256      \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 11, 9, 64)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 11, 9, 64)         0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 10, 8, 128)        32896     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 5, 4, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 5, 4, 128)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_2  (None, 128)               0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43699 (170.70 KB)\n",
            "Trainable params: 43699 (170.70 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "8/8 [==============================] - 3s 198ms/step - loss: 2.3317 - accuracy: 0.2750 - val_loss: 1.0559 - val_accuracy: 0.3667\n",
            "Epoch 2/150\n",
            "8/8 [==============================] - 1s 170ms/step - loss: 1.4367 - accuracy: 0.3625 - val_loss: 1.1378 - val_accuracy: 0.3667\n",
            "Epoch 3/150\n",
            "8/8 [==============================] - 1s 172ms/step - loss: 1.1881 - accuracy: 0.3833 - val_loss: 1.0056 - val_accuracy: 0.7167\n",
            "Epoch 4/150\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 1.1029 - accuracy: 0.4208 - val_loss: 0.9855 - val_accuracy: 0.6833\n",
            "Epoch 5/150\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 1.0469 - accuracy: 0.4625 - val_loss: 0.9353 - val_accuracy: 0.7333\n",
            "Epoch 6/150\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 1.0293 - accuracy: 0.4917 - val_loss: 0.8658 - val_accuracy: 0.7333\n",
            "Epoch 7/150\n",
            "8/8 [==============================] - 1s 171ms/step - loss: 0.8618 - accuracy: 0.6208 - val_loss: 0.7915 - val_accuracy: 0.7833\n",
            "Epoch 8/150\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 0.7688 - accuracy: 0.6667 - val_loss: 0.6980 - val_accuracy: 0.9167\n",
            "Epoch 9/150\n",
            "8/8 [==============================] - 1s 171ms/step - loss: 0.6685 - accuracy: 0.7167 - val_loss: 0.5938 - val_accuracy: 0.7667\n",
            "Epoch 10/150\n",
            "8/8 [==============================] - 1s 165ms/step - loss: 0.5676 - accuracy: 0.7708 - val_loss: 0.4821 - val_accuracy: 1.0000\n",
            "Epoch 11/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.4887 - accuracy: 0.8208 - val_loss: 0.3872 - val_accuracy: 1.0000\n",
            "Epoch 12/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.5045 - accuracy: 0.7375 - val_loss: 0.3870 - val_accuracy: 0.7500\n",
            "Epoch 13/150\n",
            "8/8 [==============================] - 1s 168ms/step - loss: 0.4324 - accuracy: 0.7958 - val_loss: 0.2984 - val_accuracy: 0.8833\n",
            "Epoch 14/150\n",
            "8/8 [==============================] - 2s 198ms/step - loss: 0.3445 - accuracy: 0.8417 - val_loss: 0.3333 - val_accuracy: 0.9000\n",
            "Epoch 15/150\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.2813 - accuracy: 0.9042 - val_loss: 0.2104 - val_accuracy: 1.0000\n",
            "Epoch 16/150\n",
            "8/8 [==============================] - 2s 238ms/step - loss: 0.3100 - accuracy: 0.8417 - val_loss: 0.2248 - val_accuracy: 0.9833\n",
            "Epoch 17/150\n",
            "8/8 [==============================] - 1s 155ms/step - loss: 0.2536 - accuracy: 0.9000 - val_loss: 0.1494 - val_accuracy: 1.0000\n",
            "Epoch 18/150\n",
            "8/8 [==============================] - 1s 155ms/step - loss: 0.1709 - accuracy: 0.9667 - val_loss: 0.1285 - val_accuracy: 1.0000\n",
            "Epoch 19/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.1665 - accuracy: 0.9458 - val_loss: 0.1445 - val_accuracy: 1.0000\n",
            "Epoch 20/150\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.1764 - accuracy: 0.9208 - val_loss: 0.1304 - val_accuracy: 1.0000\n",
            "Epoch 21/150\n",
            "8/8 [==============================] - 1s 164ms/step - loss: 0.1500 - accuracy: 0.9500 - val_loss: 0.0747 - val_accuracy: 1.0000\n",
            "Epoch 22/150\n",
            "8/8 [==============================] - 1s 155ms/step - loss: 0.1389 - accuracy: 0.9583 - val_loss: 0.0654 - val_accuracy: 1.0000\n",
            "Epoch 23/150\n",
            "8/8 [==============================] - 1s 163ms/step - loss: 0.0978 - accuracy: 0.9750 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
            "Epoch 24/150\n",
            "8/8 [==============================] - 2s 196ms/step - loss: 0.0853 - accuracy: 0.9750 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
            "Epoch 25/150\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 0.0916 - accuracy: 0.9583 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
            "Epoch 26/150\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.0780 - accuracy: 0.9750 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
            "Epoch 27/150\n",
            "8/8 [==============================] - 1s 157ms/step - loss: 0.1094 - accuracy: 0.9583 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
            "Epoch 28/150\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.0852 - accuracy: 0.9875 - val_loss: 0.0697 - val_accuracy: 1.0000\n",
            "Epoch 29/150\n",
            "8/8 [==============================] - 1s 177ms/step - loss: 0.1493 - accuracy: 0.9500 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
            "Epoch 30/150\n",
            "8/8 [==============================] - 1s 171ms/step - loss: 0.0751 - accuracy: 0.9792 - val_loss: 0.0420 - val_accuracy: 1.0000\n",
            "Epoch 31/150\n",
            "8/8 [==============================] - 1s 168ms/step - loss: 0.0558 - accuracy: 0.9833 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
            "Epoch 32/150\n",
            "8/8 [==============================] - 1s 159ms/step - loss: 0.0722 - accuracy: 0.9833 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
            "Epoch 33/150\n",
            "8/8 [==============================] - 1s 158ms/step - loss: 0.0451 - accuracy: 0.9917 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
            "Epoch 34/150\n",
            "8/8 [==============================] - 2s 217ms/step - loss: 0.0450 - accuracy: 0.9875 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
            "Epoch 35/150\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.0402 - accuracy: 0.9875 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
            "Epoch 36/150\n",
            "8/8 [==============================] - 2s 226ms/step - loss: 0.0444 - accuracy: 0.9958 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 37/150\n",
            "8/8 [==============================] - 1s 157ms/step - loss: 0.0363 - accuracy: 0.9958 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 38/150\n",
            "8/8 [==============================] - 1s 183ms/step - loss: 0.0745 - accuracy: 0.9833 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
            "Epoch 39/150\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.0578 - accuracy: 0.9708 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
            "Epoch 40/150\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 0.0524 - accuracy: 0.9792 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
            "Epoch 41/150\n",
            "8/8 [==============================] - 1s 170ms/step - loss: 0.0608 - accuracy: 0.9750 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
            "Epoch 42/150\n",
            "8/8 [==============================] - 1s 173ms/step - loss: 0.0617 - accuracy: 0.9750 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
            "Epoch 43/150\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.0546 - accuracy: 0.9833 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
            "Epoch 44/150\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.0618 - accuracy: 0.9792 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
            "Epoch 45/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.0685 - accuracy: 0.9792 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 46/150\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 0.0609 - accuracy: 0.9792 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
            "Epoch 47/150\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 0.0481 - accuracy: 0.9833 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
            "Epoch 48/150\n",
            "8/8 [==============================] - 1s 165ms/step - loss: 0.0399 - accuracy: 0.9875 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 49/150\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 0.0231 - accuracy: 0.9958 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 50/150\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 0.0209 - accuracy: 0.9958 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 51/150\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.0489 - accuracy: 0.9917 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 52/150\n",
            "8/8 [==============================] - 2s 198ms/step - loss: 0.0398 - accuracy: 0.9833 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 53/150\n",
            "8/8 [==============================] - 2s 300ms/step - loss: 0.0780 - accuracy: 0.9750 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 54/150\n",
            "8/8 [==============================] - 2s 236ms/step - loss: 0.0814 - accuracy: 0.9750 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
            "Epoch 55/150\n",
            "8/8 [==============================] - 1s 168ms/step - loss: 0.0796 - accuracy: 0.9833 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 56/150\n",
            "8/8 [==============================] - 1s 155ms/step - loss: 0.0547 - accuracy: 0.9750 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 57/150\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 0.0552 - accuracy: 0.9750 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 58/150\n",
            "8/8 [==============================] - 1s 165ms/step - loss: 0.0427 - accuracy: 0.9792 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 59/150\n",
            "8/8 [==============================] - 1s 164ms/step - loss: 0.0861 - accuracy: 0.9625 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
            "Epoch 60/150\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 0.0644 - accuracy: 0.9750 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
            "Epoch 61/150\n",
            "8/8 [==============================] - 1s 155ms/step - loss: 0.0472 - accuracy: 0.9792 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 62/150\n",
            "8/8 [==============================] - 2s 231ms/step - loss: 0.0323 - accuracy: 0.9958 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 63/150\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 0.0200 - accuracy: 0.9917 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 64/150\n",
            "8/8 [==============================] - 2s 215ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 65/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.0176 - accuracy: 0.9917 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 66/150\n",
            "8/8 [==============================] - 1s 158ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 67/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 68/150\n",
            "8/8 [==============================] - 1s 177ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 69/150\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 0.0293 - accuracy: 0.9917 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 70/150\n",
            "8/8 [==============================] - 1s 158ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 71/150\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 72/150\n",
            "8/8 [==============================] - 2s 287ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 73/150\n",
            "8/8 [==============================] - 2s 268ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 74/150\n",
            "8/8 [==============================] - 2s 180ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 75/150\n",
            "8/8 [==============================] - 1s 169ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 76/150\n",
            "8/8 [==============================] - 1s 157ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 77/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 78/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 79/150\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 0.0211 - accuracy: 0.9875 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
            "Epoch 80/150\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 0.0261 - accuracy: 0.9917 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 81/150\n",
            "8/8 [==============================] - 1s 172ms/step - loss: 0.0187 - accuracy: 0.9958 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
            "Epoch 82/150\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
            "Epoch 83/150\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.0325 - accuracy: 0.9875 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
            "Epoch 84/150\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 0.0481 - accuracy: 0.9833 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 85/150\n",
            "8/8 [==============================] - 1s 159ms/step - loss: 0.0499 - accuracy: 0.9792 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 86/150\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 0.0212 - accuracy: 0.9875 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 87/150\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 0.0222 - accuracy: 0.9958 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 88/150\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 0.0253 - accuracy: 0.9875 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 89/150\n",
            "8/8 [==============================] - 1s 159ms/step - loss: 0.0056 - accuracy: 0.9958 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 90/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 91/150\n",
            "8/8 [==============================] - 1s 178ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 92/150\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.0297 - accuracy: 0.9917 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 93/150\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.0192 - accuracy: 0.9917 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 94/150\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 95/150\n",
            "8/8 [==============================] - 1s 173ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 96/150\n",
            "8/8 [==============================] - 1s 158ms/step - loss: 0.0105 - accuracy: 0.9958 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 97/150\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.0150 - accuracy: 0.9875 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 98/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.0320 - accuracy: 0.9833 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 99/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.0448 - accuracy: 0.9750 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 100/150\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 0.0094 - accuracy: 0.9958 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 101/150\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 102/150\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 0.0088 - accuracy: 0.9958 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 103/150\n",
            "8/8 [==============================] - 2s 232ms/step - loss: 0.0263 - accuracy: 0.9917 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 104/150\n",
            "8/8 [==============================] - 1s 168ms/step - loss: 0.0356 - accuracy: 0.9875 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 105/150\n",
            "8/8 [==============================] - 1s 157ms/step - loss: 0.1542 - accuracy: 0.9375 - val_loss: 0.0343 - val_accuracy: 0.9833\n",
            "Epoch 106/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.1870 - accuracy: 0.9250 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 107/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.1085 - accuracy: 0.9583 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
            "Epoch 108/150\n",
            "8/8 [==============================] - 1s 159ms/step - loss: 0.0879 - accuracy: 0.9667 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 109/150\n",
            "8/8 [==============================] - 1s 179ms/step - loss: 0.0475 - accuracy: 0.9917 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 110/150\n",
            "8/8 [==============================] - 1s 170ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 111/150\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 0.0094 - accuracy: 0.9958 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 112/150\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 113/150\n",
            "8/8 [==============================] - 2s 183ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 114/150\n",
            "8/8 [==============================] - 1s 155ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 115/150\n",
            "8/8 [==============================] - 1s 179ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 116/150\n",
            "8/8 [==============================] - 1s 158ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 117/150\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 118/150\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 119/150\n",
            "8/8 [==============================] - 1s 160ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 120/150\n",
            "8/8 [==============================] - 1s 169ms/step - loss: 0.0095 - accuracy: 0.9958 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 121/150\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.0089 - accuracy: 0.9958 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 122/150\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 123/150\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 124/150\n",
            "8/8 [==============================] - 1s 153ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 125/150\n",
            "8/8 [==============================] - 1s 168ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 126/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 127/150\n",
            "8/8 [==============================] - 1s 168ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 128/150\n",
            "8/8 [==============================] - 1s 159ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 129/150\n",
            "8/8 [==============================] - 1s 172ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 130/150\n",
            "8/8 [==============================] - 1s 176ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 131/150\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.0057 - accuracy: 0.9958 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 132/150\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 133/150\n",
            "8/8 [==============================] - 1s 169ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 134/150\n",
            "8/8 [==============================] - 1s 153ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 135/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 136/150\n",
            "8/8 [==============================] - 1s 155ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 137/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 138/150\n",
            "8/8 [==============================] - 1s 157ms/step - loss: 0.0045 - accuracy: 0.9958 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 139/150\n",
            "8/8 [==============================] - 1s 158ms/step - loss: 0.0078 - accuracy: 0.9958 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 140/150\n",
            "8/8 [==============================] - 1s 187ms/step - loss: 0.0113 - accuracy: 0.9917 - val_loss: 8.5351e-04 - val_accuracy: 1.0000\n",
            "Epoch 141/150\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 142/150\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 143/150\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 144/150\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 8.2960e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/150\n",
            "8/8 [==============================] - 1s 168ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 146/150\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 147/150\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 148/150\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 149/150\n",
            "8/8 [==============================] - 1s 172ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 150/150\n",
            "8/8 [==============================] - 2s 231ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Training completed in time:  0:04:23.234445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 데이터 정확도\n",
        "# Evaluating the model on the training and testing set\n",
        "score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n45ecr_ybuc",
        "outputId": "8989dac9-5819-44d1-ad7d-57aea3ebe063"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  1.0\n",
            "Testing Accuracy:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "wav, sr = librosa.load('/content/drive/MyDrive/CSE/trainset/쿵_54.wav')\n",
        "mfcc = librosa.feature.mfcc(y=wav, sr=sr, n_mfcc=100)\n",
        "pad_width = 86 - mfcc.shape[1]\n",
        "mfcc = np.pad(mfcc, pad_width=((0,0), (0,pad_width)),mode='constant')\n",
        "mfcc= np.expand_dims(mfcc, 0)\n",
        "\n",
        "check = model.predict(mfcc)[0].tolist()\n",
        "cc = check.index(max(check))\n",
        "if cc==0: print('덕')\n",
        "elif cc==1: print('덩')\n",
        "elif cc==2: print('쿵')\n",
        "\n",
        "#y_prob = model.predict(mfcc)\n",
        "#predicted_vector = y_prob.argmax(axis=-1)\n",
        "#predicted_class = le.inverse_transform(predicted_vector)\n",
        "#print(\"The predicted class is:\",predicted_class[0])\n",
        "\n",
        "#[[덕],[덩],[쿵]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU0tgOEwymKb",
        "outputId": "269e3a9c-1254-4ad8-8c86-c3f412b10b54"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 139ms/step\n",
            "쿵\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('/content/drive/My Drive/CSE/1028.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aI2fB8odiZUj",
        "outputId": "5fdab084-6549-4c50-edc6-737894929089"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}